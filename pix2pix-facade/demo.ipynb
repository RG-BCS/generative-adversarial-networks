{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pix2Pix on Facade Dataset â€” Demo Notebook\n",
        "\n",
        "This notebook demonstrates how to train and evaluate a Pix2Pix model for image-to-image translation on the **CMP Facade Dataset**. The model learns to generate building facade labels from photos using conditional GANs.\n",
        "\n",
        "We use a standard U-Net-based generator and PatchGAN-based discriminator. Training is done using the combined L1 + adversarial loss, following the original Pix2Pix paper.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LKoulLBlsPs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and helper imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import from your module files\n",
        "from model import Pix2Pix_Model\n",
        "from dataset_preprocess import train_dataset, test_dataset\n",
        "from utils import train_model, compute_metrics, evaluate_on_testset\n"
      ],
      "metadata": {
        "id": "Cly-nZXnsWXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility\n",
        "\n",
        "We set random seeds for consistent results across runs.\n"
      ],
      "metadata": {
        "id": "9ghHJIzJsirZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 32\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n"
      ],
      "metadata": {
        "id": "5FhgxnPqsl8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "\n",
        "Define number of epochs, learning rate, and optimizers for generator and discriminator.\n"
      ],
      "metadata": {
        "id": "VNnPXYkosn_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 200\n",
        "LEARNING_RATE = 2e-4\n",
        "BETA_1 = 0.5\n",
        "\n",
        "model_pix2pix = Pix2Pix_Model()\n",
        "gen_optimizer = keras.optimizers.Adam(LEARNING_RATE, BETA_1)\n",
        "disc_optimizer = keras.optimizers.Adam(LEARNING_RATE, BETA_1)\n"
      ],
      "metadata": {
        "id": "BuNEYFDysqKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Pix2Pix Model\n",
        "\n",
        "Start training the generator and discriminator on the facades dataset.\n",
        "Losses and gradient norms will be logged every 10 epochs.\n"
      ],
      "metadata": {
        "id": "X76li1H_sucf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_losses, disc_losses, gen_grad_norms, disc_grad_norms, gen_gan_losses, gen_l1_losses = \\\n",
        "    train_model(model_pix2pix, gen_optimizer, disc_optimizer,\n",
        "                train_dataset, NUM_EPOCHS, clip_norm=False, max_norm=1.0)\n"
      ],
      "metadata": {
        "id": "tiSDHSJ4sxzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Metrics\n",
        "\n",
        "Let's plot:\n",
        "- Generator and Discriminator Loss\n",
        "- Generator GAN loss and L1 loss\n",
        "- Gradient norms for both networks\n"
      ],
      "metadata": {
        "id": "Lf6OWlcCs0Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"gen_loss\": gen_losses,\n",
        "    \"disc_loss\": disc_losses,\n",
        "    \"gen_gan\": gen_gan_losses,\n",
        "    \"gen_l1\": gen_l1_losses,\n",
        "    \"gen_grad_norm\": gen_grad_norms,\n",
        "    \"disc_grad_norm\": disc_grad_norms\n",
        "})\n",
        "\n",
        "# Plot gradient norms\n",
        "df[['gen_grad_norm', 'disc_grad_norm']].plot(figsize=(8, 5), title=\"Gradient Norms\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L2 Norm\")\n",
        "plt.show()\n",
        "\n",
        "# Plot losses\n",
        "df[['gen_loss', 'disc_loss', 'gen_gan', 'gen_l1']].plot(figsize=(8, 5), title=\"Generator and Discriminator Loss\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LLLIkMNns4uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Pix2Pix on Test Set\n",
        "\n",
        "We compute:\n",
        "- **PSNR (Peak Signal-to-Noise Ratio)**\n",
        "- **SSIM (Structural Similarity Index)**\n",
        "\n",
        "Then visualize predictions from a few test samples.\n"
      ],
      "metadata": {
        "id": "-xWXs-rys87B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrics(model_pix2pix, test_dataset)\n",
        "evaluate_on_testset(model_pix2pix, test_dataset, num_examples=10, save_images=False)\n"
      ],
      "metadata": {
        "id": "r-RA9PcUtBGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we:\n",
        "\n",
        "- Trained a **Pix2Pix** model on the **CMP Facade Dataset**\n",
        "- Used a U-Net generator and PatchGAN discriminator\n",
        "- Monitored training loss, gradient norms, and visual outputs\n",
        "- Evaluated the model using **PSNR** and **SSIM**\n",
        "\n",
        "This project demonstrates the effectiveness of conditional GANs for structured image-to-image tasks. To further improve results, consider:\n",
        "\n",
        "- Increasing training epochs\n",
        "- Using better regularization or data augmentation\n",
        "- Testing on other datasets like edges2shoes or maps\n",
        "\n",
        "---\n",
        "\n",
        "*Happy experimenting!*\n"
      ],
      "metadata": {
        "id": "Bv918_mqtAr1"
      }
    }
  ]
}