{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Super-Resolution GAN Demo with WGAN-GP on DIV2K Dataset\n",
        "\n",
        "This notebook demonstrates training a Wasserstein GAN with Gradient Penalty (WGAN-GP) for image super-resolution using the DIV2K dataset.\n",
        "\n",
        "The model learns to generate high-resolution images from low-resolution inputs, evaluated using perceptual metrics like PSNR and SSIM.\n",
        "\n",
        "We will:\n",
        "- Set up the environment\n",
        "- Define and initialize the model\n",
        "- Train the model\n",
        "- Visualize training progress\n",
        "- Show example super-resolved images\n"
      ],
      "metadata": {
        "id": "ycL7-zk_hQ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import train_wgan_with_gp_model_2, show_super_resolution\n",
        "from dataloader_generator import train_dl, valid_dl\n",
        "from model import WGAN_GP_Div2k_2  # Adjust if needed\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "Zfi_XaPShXd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set random seed and hyperparameters\n"
      ],
      "metadata": {
        "id": "DD8pDvK1hkGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 43\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "num_epochs = 100\n",
        "lambda_gp = 10\n",
        "n_filters = 128\n",
        "learning_rate = 1e-3\n"
      ],
      "metadata": {
        "id": "heoPsPhOhlBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize model and optimizers\n"
      ],
      "metadata": {
        "id": "2fUthzgKhn6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model_res = WGAN_GP_Div2k_2(n_filters=n_filters, dropout=0.1, negative_slope=0.2, skip_connect=True).to(device)\n",
        "\n",
        "# Define separate optimizers\n",
        "gen_optim_res = torch.optim.Adam(model_res.gen_model.parameters(), lr=learning_rate)\n",
        "disc_optim_res = torch.optim.Adam(model_res.disc_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "q1228Kkahp38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n"
      ],
      "metadata": {
        "id": "MD1mwmlghtd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_train_loss, disc_train_loss, gen_val_loss, disc_val_loss = train_wgan_with_gp_model_2(\n",
        "    model_res, gen_optim_res, disc_optim_res, num_epochs, train_dl, valid_dl,\n",
        "    lambda_gp=lambda_gp,\n",
        "    clip_norm_disc=True,\n",
        "    clip_norm_gen=True,\n",
        "    norm_max_disc=20.0,\n",
        "    norm_max_gen=20.0,\n",
        "    n_critic=2,\n",
        "    apply_recon_loss=True,\n",
        "    recon_loss_weight=200.0,\n",
        "    apply_noise_to_real=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "br9g9l69huWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training and validation loss curves\n"
      ],
      "metadata": {
        "id": "HnZRfMjmhxuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {\n",
        "    'gen_train_loss': gen_train_loss,\n",
        "    'disc_train_loss': disc_train_loss,\n",
        "    'gen_val_loss': gen_val_loss,\n",
        "    'disc_val_loss': disc_val_loss\n",
        "}\n",
        "pd.DataFrame(history).plot()\n",
        "plt.grid()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qOm9e0qHh0Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show super-resolved images on training set\n"
      ],
      "metadata": {
        "id": "CwfiZ2XSh2b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample images from train set after model is trained\")\n",
        "show_super_resolution(model_res, dataloader=train_dl, num_images=8, calculate_quantitative=False, random_sample=True)\n"
      ],
      "metadata": {
        "id": "gywGi2f7h5CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show super-resolved images on validation set\n"
      ],
      "metadata": {
        "id": "GkT60rzuh9pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSample images from valid set after model is trained\")\n",
        "show_super_resolution(model_res, dataloader=valid_dl, num_images=8, calculate_quantitative=False, random_sample=True)\n"
      ],
      "metadata": {
        "id": "cp6hsHqZh_4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "The WGAN-GP model has been trained to generate high-resolution images from low-resolution inputs.\n",
        "The training and validation loss curves indicate model convergence.\n",
        "Sample super-resolved images demonstrate the model's ability to enhance low-resolution inputs visually.\n",
        "\n",
        "Further improvements could involve experimenting with different architectures, loss weights, and augmentations.\n"
      ],
      "metadata": {
        "id": "pNrx8LgFiH8O"
      }
    }
  ]
}